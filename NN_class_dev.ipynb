{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN_class_dev.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leonSadowski/sc_Hierarchical_Classifier/blob/main/NN_class_dev.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import tensorflow as tf \n",
        "import tensorflow.keras as keras \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "import networkx as nx"
      ],
      "metadata": {
        "id": "XAInitxPwiAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create Class for local (NN) classifier**"
      ],
      "metadata": {
        "id": "FeZG7IAvwWzS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0eeCUgYwORc"
      },
      "outputs": [],
      "source": [
        "class Neural_Network():\n",
        "\n",
        "  def __init__(self, \n",
        "               x_input_data,\n",
        "               y_input_data,\n",
        "               z_transform_input = True,\n",
        "               list_of_hidden_layer_nodes = [30],\n",
        "               activation_function = 'relu',\n",
        "               learning_rate = 0.001,\n",
        "               momentum = .9,\n",
        "               loss_function = 'categorical_crossentropy',\n",
        "               epochs = 50):\n",
        "    \n",
        "    self.x_input_data = x_input_data\n",
        "    self.y_input_data = y_input_data\n",
        "    self.list_of_layer_nodes = [len(self.x_input_data[0])] + [nodes for nodes in list_of_hidden_layer_nodes] + [len(self.y_input_data.cat.categories)] \n",
        "    self.activation_function = activation_function \n",
        "    self.learning_rate = learning_rate\n",
        "    self.momentum = momentum\n",
        "    self.loss_function = loss_function\n",
        "    self.epochs = epochs\n",
        "    self.z_transform_input = z_transform_input\n",
        "\n",
        "    #create model\n",
        "\n",
        "    self.model = keras.models.Sequential()\n",
        "\n",
        "    for nodes, layer_idx in zip(self.list_of_layer_nodes, range(0, len(self.list_of_layer_nodes)-1)):\n",
        "\n",
        "      self.model.add(keras.layers.Dense(\n",
        "          input_shape = (nodes,),\n",
        "          units = self.list_of_layer_nodes[layer_idx+1],                            #Ausgabeknotenanzahl == Anzahl Knoten der nächsten Schicht\n",
        "          kernel_initializer = 'glorot_uniform',                                    #default      \n",
        "          bias_initializer = 'zeros',                                               #werden die im fit berücksichtigt?\n",
        "          activation = self.activation_function if layer_idx == 0 else 'softmax'))  #actication als default 'relu', in letzter schicht 'softmax'\n",
        "        \n",
        "\n",
        "  def process_input_data(self):\n",
        "\n",
        "    #z transformation \n",
        "\n",
        "    def z_transform_properties(data_arr):\n",
        "      '''Calculates a z transformation to center properties across cells in data_arr around mean zero'''\n",
        "      \n",
        "      mean_vals = np.mean(data_arr, axis=0)\n",
        "      std_val = np.std(data_arr)\n",
        "\n",
        "      data_transformed = (data_arr - mean_vals) / std_val\n",
        "\n",
        "      return data_transformed\n",
        "\n",
        "\n",
        "    if self.z_transform_input:\n",
        "      \n",
        "      self.x_input_data = z_transform_properties(self.x_input_data)\n",
        "\n",
        "    #converting labels of y_input_data to integers (mapping 'label'->int)\n",
        "\n",
        "    if isinstance(self.y_input_data, pd.Series):\n",
        "      #encode categorical labels from pandas Series as integers\n",
        "      self.label_encoder = LabelEncoder()\n",
        "      self.y_input_data_int = self.label_encoder.fit_transform(self.y_input_data.values)\n",
        "\n",
        "    elif isinstance(self.y_input_data[0], np.array) and isinstance(self.y_input_data.dtype == int):\n",
        "      self.y_input_data_int = self.y_input_data\n",
        "\n",
        "    else:\n",
        "\n",
        "      print('Error: Invalid or unknown Data Type for Y Input data')\n",
        "\n",
        "  \n",
        "\n",
        "    #split data (TO DO: implement scikit.learn cross_val_score for k-fold cross validation)\n",
        "\n",
        "    split_data_index = int(2/3 * len(self.x_input_data))\n",
        "\n",
        "    self.x_training_input = self.x_input_data[ : split_data_index]\n",
        "    self.y_training_input_int = self.y_input_data_int[ : split_data_index]\n",
        "\n",
        "    self.x_test_input = self.x_input_data[split_data_index : ]\n",
        "    self.y_test_input_int = self.y_input_data_int[split_data_index : ]\n",
        "\n",
        "    #use integer y_input data for OneHot Encoding (int -> e_i element R^(int+1)) needed for model training\n",
        "\n",
        "    self.y_training_onehot = keras.utils.to_categorical(self.y_training_input_int)\n",
        "    self.y_test_onehot = keras.utils.to_categorical(self.y_test_input_int)\n",
        "\n",
        "\n",
        "  def train(self):\n",
        "    '''Train the NN using the x_training_data input and onehot encoded y_training_onehot'''\n",
        "\n",
        "    self.optimizer = keras.optimizers.SGD(learning_rate = self.learning_rate, momentum = self.momentum)\n",
        "    \n",
        "    self.model.compile(optimizer = self.optimizer, loss = self.loss_function)\n",
        "\n",
        "    history = self.model.fit(self.x_training_input, self.y_training_onehot,\n",
        "                        batch_size = 64, epochs = self.epochs, \n",
        "                        verbose = 1,\n",
        "                        validation_split = .1)\n",
        "    \n",
        "  def predict(self, input_vec):\n",
        "    '''Calculate and return label prediction of trained model for an input vector\n",
        "        input_vec (dtype=int)'''\n",
        "\n",
        "    pred_vec = np.argmax(self.model.predict(input_vec), axis = -1) #-1?\n",
        "\n",
        "    return pred_vec\n",
        "\n",
        "\n",
        "  def validate(self):\n",
        "\n",
        "    self.y_training_preds = self.predict(self.x_training_input)\n",
        "    self.y_test_preds = self.predict(self.x_test_input) \n",
        "\n",
        "    def calc_acc(pred_vec, known_vec):\n",
        "      \n",
        "      if type(pred_vec) == type(known_vec):\n",
        "        acc = np.sum(pred_vec == known_vec, axis = 0) / len(known_vec)\n",
        "      else:\n",
        "        print('self.validate: Error! Comparison of different label encoding!')\n",
        "      \n",
        "      return acc\n",
        "\n",
        "    self.train_acc = calc_acc(self.y_training_preds, self.y_training_input_int) \n",
        "    self.test_acc = calc_acc(self.y_test_preds, self.y_test_input_int)\n",
        "\n",
        "\n",
        "  def local_classifier_output(self):\n",
        "    '''Evaluate all relevant output of this local classifier\n",
        "    e.g.:\n",
        "    self.process_input_data()\n",
        "    self.train()\n",
        "    self.validate()'''\n",
        "\n",
        "    pass\n",
        "\n",
        "    #missing: potential decoding int->'label', dtype='category'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Parent_Node():\n",
        "\n",
        "#    need attributes: \n",
        "#      - input data to local classifier\n",
        "#      -output vector (predicitions) of following(?) local classifer\n",
        "#      \n",
        "#      need methods:\n",
        "#      - run local calssifier model (best case: generate relevant information for initializing neural network\n",
        "#      from given list/dict, which defines the subsets, e.g {'TNK':[CD4T, CD8T], etc})\n",
        "\n",
        "  def __init__(self, x_input_data, y_input_data):\n",
        "    '''Params:\n",
        "      - input_data: pd.Series from AnnData Object or np.array,dtype=int -> local classifier will take care of that\n",
        "    '''\n",
        "\n",
        "    self.x_input_data = x_input_data\n",
        "    self.y_input_data = y_input_data\n",
        "\n",
        "    self.local_classifier = Neural_Network(self.x_input_data, self.y_input_data)\n",
        "\n",
        "    def run_local_classifier(self):\n",
        "\n",
        "      self.local_classifier.train()\n",
        "\n",
        "      #save prediction vector of this local classifier (notice: len(self.children_node_predictions) = #nodes in next level)\n",
        "      self.children_node_predictions = self.local_classifier.predict(self.local_classifier.x_test_input)\n",
        "\n",
        "     \n",
        "\n",
        "\n",
        "#use Parent_Node() objects in hierarchical classifier -> implement network of parent node objects"
      ],
      "metadata": {
        "id": "o_AXxnDv4rQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Node_Memory():\n",
        "\n",
        "  def __init__(self, x_input_data = None, y_input_data = None, local_classifier = None, local_classifier_params = []):\n",
        "\n",
        "      #local_classifier argument is the Class of classifier (eg Neural_Network (classifier specific params, input and output needed for every possible classifier))\n",
        "      \n",
        "      self.x_input_data = x_input_data #processing wird von local classifier übernommen (CAVE bei Verwendung anderer LC (eg SVM), dass preprocessing einheitlich ist)\n",
        "      self.y_input_data = y_input_data \n",
        "\n",
        "      if local_classifier != None:\n",
        "        self.local_classifier = local_classifier(self.x_input_data, self.y_input_data, *local_classifier_params)\n",
        "      \n",
        "      self.noderelevant_input_data_indices = None #save indices of data in input vector, that will be used for prediction in order to compute accuracy\n",
        "      self.prediction_vec = None\n",
        "\n",
        "    \n",
        "  def run_local_classifier(self):\n",
        "\n",
        "    self.local_classifier.train()\n",
        "  \n",
        "  def local_classifier_prediction(self, input_vec): #hier muss noch was passieren, prediction von außen für bestimmte inputs aufrufen\n",
        "\n",
        "    self.local_classifier.predict(input_vec)\n",
        "\n",
        "  def subsetting_of_prediction_vector(self):\n",
        "    pass"
      ],
      "metadata": {
        "id": "sZJiCqeZ0gKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_graph_from_edges(d, g, parent_key=''):\n",
        "    for key in d.keys():\n",
        "        if parent_key != '':\n",
        "            g.add_edge(parent_key, key)\n",
        "        if len(d[key]) == 0:\n",
        "            pass\n",
        "        else:\n",
        "            make_graph_from_edges(d[key], g, parent_key=key)"
      ],
      "metadata": {
        "id": "sUU8Yb1TmIUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Hierarchical_Classifier():\n",
        "  '''Class connects Nodes of Local Classifiers, passes results to children classifiers and forms the final hierarchical classifier''' \n",
        "\n",
        "  def __init__(self, dict_of_cell_relations):\n",
        "    '''Params\n",
        "        - dict_of_cell_relations: used for initializing network structure of hierarchical classifier'''\n",
        "    self.dict_of_cell_relations = dict_of_cell_relations\n",
        "\n",
        "\n",
        "  def make_classifier_graph(self):\n",
        "    '''Compute Graph from a given dictionary of cell relationships'''\n",
        "    self.graph = nx.DiGraph()\n",
        "    make_graph_from_edges(self.dict_of_cell_relations, self.graph)\n",
        "\n",
        "  def init_node_memory_object(self, node, memory_class_params=[]):\n",
        "    '''Add memory object to each node; memory object organizes all relevant local classifier params'''\n",
        "    self.graph.add_node(node, memory=Node_Memory(*memory_class_params))\n",
        "\n",
        "  def subset_pred_vec(self, node):\n",
        "    next_labels = [label for label in self.graph[node].keys()]\n",
        "    print(next_labels)\n",
        "    for next_label in next_labels:\n",
        "      print('bin in schleife')\n",
        "      temp_idx_vec = np.where(self.graph.nodes[node]['memory'].prediction_vec == next_label)\n",
        "\n",
        "      print(self.graph.nodes[node]['memory'].prediction_vec)\n",
        "\n",
        "      print(temp_idx_vec)\n",
        "      self.graph.nodes[next_label]['memory'].x_input_data = self.graph.nodes[node]['memory'].x_input_data[temp_idx_vec]\n",
        "\n"
      ],
      "metadata": {
        "id": "IQaUTDTS_X1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "    # for next_label in next_labels:\n",
        "    #   print('bin in schleife')\n",
        "    #   temp_idx_vec = np.where(self.graph.nodes[node]['memory'].prediction_vec == next_label)\n",
        "    #   self.graph.nodes[next_label]['memory'].x_input_data = self.graph.nodes[node]['memory'].x_input_data[temp_idx_vec]"
      ],
      "metadata": {
        "id": "mW_PhU59OYUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    '''in methode subset_pred_vec:'''\n",
        "    # return next_labels\n",
        "\n",
        "    # damit for schleife für wirkliche pred_vec's funktioniert (insb der temp_idx_vec) muss die liste it ints mit dem decoder wieder in \n",
        "    # string labels umgeschrieben werden !"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fzXlq28ZOQuI",
        "outputId": "e4a900b0-a269-4ded-914d-2d0a9f2b010e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'in methode subset_pred_vec:'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "  # def subset_pred_vec(self, node):\n",
        "  #   '''Method of HC in order to have access to labels of neighboring nodes of one node -> automatic subsetting\n",
        "  #      Requires already initialized memory attribute, which is given in case that the classifier has already been run'''\n",
        "\n",
        "  #   neighbor_labels = [key for key in self.graph[node].keys()] \n",
        "\n",
        "  #   return neighbor_labels\n",
        "\n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "id": "NLqUdSycFnzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**#######################################################**\n",
        "**Messy Test bereich**"
      ],
      "metadata": {
        "id": "K-hKrllEGSri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hc = Hierarchical_Classifier({'all': {'tnk':{'cd4t':{}, 'cd8t':{}}, 'm':{'cd17':{}, 'fc':{}}}})"
      ],
      "metadata": {
        "id": "AopRfZquzw_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hc.make_classifier_graph()"
      ],
      "metadata": {
        "id": "QfFjEg9JaXFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nx.draw(hc.graph, with_labels=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "9MZEfZj29EKu",
        "outputId": "9fc639a9-4fdc-4860-bc4e-c034930f8312"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb4AAAEuCAYAAADx63eqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deVxVdeL/8deFy6qgpqgYoKYp2eSCSGbj2mZqOV8VF1zB0rTf2ExaZk1TljqVM2WWhJmAW7lgy2ja5IbLqLnlkoqGZUAioImIAnKX3x+OFLkrcC73vp+PxzweAvec3nce4vt+Puecz8dkt9vtiIiIuAg3owOIiIhUJBWfiIi4FBWfiIi4FBWfiIi4FBWfiIi4FBWfiIi4FBWfiIi4FBWfiIi4FBWfiIi4FBWfiIi4FBWfiIi4FBWfiIi4FBWfiIi4FBWfiIi4FBWfiIi4FBWfiIi4FBWfiIi4FBWfiIi4FBWfiIi4FBWfiIi4FBWfiIi4FBWfiIi4FLPRAURcwYn8IpJ2ZpByPI+8Qgv+3mZC6/oT2TqImlW9jI4n4lJMdrvdbnQIEWe1Jz2XGcmprD+cA0CRxVbyM2+zG3agU9MARndsTIvg6galFHEtKj6RcjJ/61Emr0ih0GLlar9lJhN4m915qVsog9o2qLB8Iq5KU50i5eBC6R2koNhG8ckMcr54E0vucap3GIx/+OOlXmu3Q0GxlckrDgKo/ETKmUZ8ImVsT3ou/WdtpaDYCsCJFe/i5unLbQ8+ec1jfTzcWTSiLc2DNO0pUl50V6dIGZuRnEqhxVrytfV0Nh4BIdd1bKHFSmxyanlFExE04hMpUyfyi7j/zbUlN7Ec//hFitK/Azd3TG7u1B30FvnfreXcof9iKzqLZ0ADavd7HTePX+/s9DK7sXl8F93tKVJOdI1PpAwl7cwo9XXdqCkcX/ACVf7QGb8Wj3Dy6w8ozvmJuoOn4l6lBkXHDmMylZ54MQFJuzIY2aFRBSYXcR2a6hQpQynH80o9svBbdruNs3tXcduDIzD71cLk5o530F2YzB6lXldosZGSeaYi4oq4JBWfSBnKK7Rc8We2c3nYLecx1wi8jvMUl2UsEfkNFZ9IGfL3vvLVAzdff0xmTyynMq/jPB7XfI2I3BwVn0gZCq3rj5f58r9WJpMbVZo/xKm1H2E5cxK7zUrRzwexW0qP7rzNboQG+lVEXBGXpOITKUN9Wgdd9ec1OsfgEdCA43P+Svq7Azi1LhG7vfQ1QTvQJ+zq5xGRm6fHGUTK2Ih5O1h1MOuqy5RdickEjzSrQ9yg8LIPJiKAik+kzP1+5ZYbYjlPzT3z6PdgW1q1akXLli0JCAgo+5AiLkzFJ1IOfrtW5/Xy8XCj9s+b2BA/BTc3N6pWrcqZM2eYNWsWw4cPL8e0Iq5FxSdSTm5md4aH7/Clfv36FBYWAlC7dm0OHz5MtWrVKii1iPPTzS0i5WRQ2wYsGtGWR5rVwcvshvfv7vb0NrvhZXbjkWZ1WDSiLYPaNqB27do88cQTmM1mzGYzdrud3bt3G/QORJyTRnwiFeBkfhFJuzJIyTxDXmEx/t4ehAb60Sfs0h3Yjx8/Tv369Zk2bRp33HEHw4YNY8yYMYwfPx43N31WFblVKj4RB5SdnU1AQAAmk4mMjAz69+9PtWrVmDt3LjVr1jQ6nkilpo+PIg6odu3amEwmAIKCgli3bh3NmjUjLCyMrVu3GpxOpHLTiE+kEvniiy8YMWIEEyZM4JlnnikpRxG5fio+kUrmxx9/pG/fvoSEhBAfH687PkVukKY6RSqZhg0bsmnTJgIDA2ndujXffvut0ZFEKhUVn0gl5OXlxfvvv8/kyZN5+OGHmTlzJpq8Ebk+muoUqeQOHTpEZGQkzZs3Jy4ujqpVqxodScShacQnUsk1bdqUrVu34uXlRZs2bdi/f7/RkUQcmopPxAn4+voye/Zsxo8fT6dOnZg3b57RkUQclqY6RZzMvn37iIyMpH379kyfPh0fHx+jI4k4FI34RJzMPffcw/bt28nPz6dt27Z8//33RkcScSgqPhEn5Ofnx8cff8xTTz1Fu3btWLJkidGRRByGpjpFnNzOnTuJjIykR48eTJ06FS8vr2sfJOLENOITcXKtW7dm165dpKen0759e44ePWp0JBFDqfhEXED16tX59NNP6d+/P/feey/Lly83OpKIYTTVKeJiNm/eTP/+/RkwYACTJk3Cw8PD6EgiFUrFJ+KCTpw4weDBg8nPz2fhwoXcfvvtRkcSqTCa6hRxQbVq1eLLL7+ka9euhIeHs2rVKqMjiVQYjfhEXNy6desYNGgQTz75JC+//DLu7u5GRxIpVyo+ESEzM5MBAwbg4eHBggULqF27ttGRRMqNpjpFhMDAQFavXs29995LWFgYGzduNDqSSLnRiE9ESlm5ciXR0dH89a9/5bnnnsPNTZ+Pxbmo+ETkEunp6fTt25datWoxZ84cbrvtNqMjiZQZfZQTkUsEBwezfv16mjRpQlhYGNu2bTM6kkiZ0YhPRK7qs88+Y+TIkfztb3/jz3/+MyaTyehIIrdExSci13TkyBEiIyNp1KgRH330EdWqVTM6kshN01SniFxTo0aN2Lx5M7Vq1SI8PJzdu3cbHUnkpqn4ROS6eHt788EHHzBx4kQeeughZs2ahSaMpDLSVKeI3LCUlBT69OlDWFgYH3zwAVWqVDE6ksh104hPRG5YaGgo33zzDSaTiYiICA4cOGB0JJHrpuITkZtSpUoVEhMTGTt2LB07dmT+/PlGRxK5LprqFJFbtnfvXvr06UPnzp1599138fb2NjqSyBVpxCcit6x58+bs2LGDU6dOcd9995Gammp0JJErUvGJSJnw9/dn0aJFPPHEE7Rr146lS5caHUnksirNVOeJ/CKSdmaQcjyPvEIL/t5mQuv6E9k6iJpVvYyOJyK/sX37dvr27UvPnj1566238PT0NDqSSAmHL7496bnMSE5l/eEcAIostpKfeZvdsAOdmgYwumNjWgRXNyiliPzeqVOnGDp0KNnZ2SxevJiQkBCjI4kADl5887ceZfKKFAotVq6W0mQCb7M7L3ULZVDbBhWWT0Suzm63869//YupU6cSHx9P9+7djY4k4rjX+C6U3kEKii+UniU3i5/e6IHdZr3ktXY7FBRbmbziIPO3Hq34sCJyWSaTiXHjxvHpp5/y1FNPMWHCBCwWi9GxxMU5ZPHtSc9l8ooUCoptV3yNteAMOZ+/Sfq0AaS/G0XOv6dyNj+fyStS2JuRi8lk0p1lIg7i/vvvZ9euXezcuZMHHniAY8eOGR1JXJhDFt+M5FQKLZeO7H4rd8M8bIX53D5qNrePnIXtbC65mxZQaLESm6zCE3E0AQEBrFy5kgcffJDw8HDWrFljdCRxUQ5RfOnp6fTq1YuAgABuu60mi6dPxGa1cmrtbNLfjeLnD4ZTcGR7qWMsp7PwbdIWNy9f3Lyr4NvkPopPpGG3w9wXhwHQokULqlatyqJFiwx4VyLye+7u7rz88svMmzePwYMH89prr2G1Xv1DrkhZM7z4rFYrPXr0oH79+hw9epSJCzfi36wj+Xv+w7nU7QRGv0vdYdM4e+i/pY7zC+vOudRtWAvzsRbmc/bQZnzuCAcgZOhUAPbs2UN+fj79+vWr8PclIlf2wAMPsGPHDtasWUO3bt3IyckxOpK4EMOLb9u2bRw7doypU6dSpUoVjpwqwq3eXZw9uAn/No9j9g/A3cePavdFljrOs04jsFrImDaAjGkDMLm54RfWDYBCy5WvDYqIY6hXrx5r1qwhLCyMsLAwNm3aZHQkcRGGF196ejr169fHbDYDkFd44Y4va/4vuPsFlLzO7F+71HEnvngT8223E/zsEoKfXYy5el1OLPtXxQUXkVtmNpv5xz/+QVxcHL179+af//yn9viTcmd48QUHB5OWllZyi7O/94UCdK9aA+uZX6c/LHmlp0LOZ/2AX8uuuHl64+bpg1+rbhQc2VFxwUWkzHTv3p1t27aRlJREz549OXXqlNGRxIkZXnwREREEBgbywgsvcPbsWRrV8MKWeZAqoe05s2MZlrwTWAvzydu6pNRxnoF3kr/na2zFRdiKiziz+ys8azcALqzo4n9bLX744QcD3pGI3Iz69euzYcMG7rjjDsLCwti+ffu1DxK5CQ6xcktaWhpjxoxh48aNgAlbo/vx7zycU2vjOfvdWkxevlSL+D9+WRVHyPNfYHJzpzj3OKdWzaTo5xTAjmdgE257aCQet92Ol9mNJ2sd4V9vTKagoIAPP/yQvn37Gv02ReQ6LV26lFGjRvHKK68wevRoTCaT0ZHEiThE8f3eiHk7WHUw66rLlF2JyQSPNKtD3KDwsg8mIhUmNTWVyMhImjRpwqxZs/D39zc6kjgJw6c6L+fpTo3xNrvf1LHeZndGd2pcxolEpKI1btyYzZs3U716ddq0acPevXuNjiROwv3VV1991egQv1e3mjfVfcxs+eEkFtv1D/t8PNx4qdtdPNSsbjmmE5GK4uHhwWOPPUaNGjWIioqiVq1atGrVyuhYUsk55FTnRde9OwPgjo2Xe9zN0PvvqLB8IlJxDhw4QGRkJG3atGHGjBlUqVLlsq/T3p1yLQ5dfAB7M3KJTU5l3aEcTJR+OP3ifnzh9XxIeu1JqllPExsbS+/evXUxXMQJnT17lqeeeopvv/2WpKQkQkNDS36mvTvlejl88V10Mr+IpF0ZpGSeIa+wGH9vD0ID/egTFkQNXw88PT2xWq34+vrSoEED4uPjuffee42OLSJlzG63M3v2bCZMmMD06dMZMGCA9u6UG1Jpiu9aGjZsyNGjR4ELq0H89a9/5a233jI2lIiUm927dxMZGUlE1Fh22etfdRuz37t4P4DKzzU55F2dN6Np06aYTCZMJhMjRoxQ6Yk4uZYtWzJnWTI7rCE3VHoABcW2kr07xfU4TfF16dKFiIgIli9fzpIlS/jpp5+MjiQi5Sxxeybnb+DO79/S3p2uy2mmOn/rrbfe4ssvv2Tt2rW4u9/c84Ai4thO5Bdx/5trS25iyYiNwa91d85+tw5Lbia+d3WgRschnPhyGkUZB/AKbEKt/5uAu3fVknN4md3YPL6L7vZ0MU4z4vutsWPHYjKZmDp1qtFRRKScJO3MuOR75w5tpk7/16k3YiYFqdvIXvwqNToMIXjMAux2O2d2/LvU601A0q5LzyPOzWx0gPLg7u7O3LlzCQ8P56GHHqJ169ZGRxKRMpZyPK/UIwsAfq174F6lBgDeQXfjVqUannUbAeDb5D4Kf9pT6vWFFhspmWcqJrA4DKcc8QGEhIQwffp0Bg4cyLlz54yOIyJl7OLenb91sfQATB6euPtWL/W1/XzBZc5TXD4BxWE5bfEB9O/fn/DwcMaNG2d0FBEpYxf37rz183iUyXmk8nDKqc7fmjFjBi1atGD58uX06NHD6DgichNWrVpFcXEx9erVIzAwkICAAELr+uNlPn7JdOeN8Da7ERroV4ZJpTJw+uKrVq0a8+bNo2/fvuzevZs6deoYHUlEbtDTTz9Neno6Hh4eFBQUYLFYGDlmHPh3uaXz2oE+YUFlE1IqDad8nOFyXnzxRfbu3cuyZcu0jqdIJWKz2Rg1ahSzZ8/GarViMpkIDg5mz549PL8sVXt3yg1z6mt8v/Xqq69y/Phx4uLijI4iItfhp59+4rXXXqNx48Zs2LABk8mEu7s7wcHB7Ny5k+rVq9/S3p12y3n6NNPmtq7IZYrP09OTBQsW8Pe//52UlBSj44jIZRQUFPDJJ5+UPIaUlZXFkiVLOHDgAB07dqR69eps2rSJWrVqAdAiuDovdQvFx+PG/inz8XDjj77ZDO7ekXXr1pXHWxEH5jJTnRfFxcUxa9YstmzZgqenp9FxRFye3W5nx44dJCQksGjRIsLDw4mJiaFnz554e3uXvC4j48KD5kFBl16Tu9ndGVavXs2gQYMYO3Ys48aN02UQF+FyxWe32+nZsyd33303//jHP4yOI+KysrOzmT9/PvHx8RQUFBAdHc2QIUMICQm5qfNdz96dnZsGMLpTY5oH/fp8X1paGr179yYkJISEhAT8/TX96excrvjgwi9cy5Yt+eSTT+jYsaPRcURcRnFxMStXriQhIYF169bxpz/9iejoaNq3b4+bW9lcebna3p1XWpOzsLCQZ555hg0bNvDpp59y1113lUkWcUwuWXwAK1asYNSoUezZs4fq1bUbs0h5OnDgAAkJCcyfP59GjRoRHR1N37598fNzrGfo4uPjGT9+PLGxsURGRhodR8qJyxYfXHg2KDc3lwULFhgdRcTpnD59mkWLFhEfH09aWhpDhw5l2LBhNG3a1OhoV7Vr1y569+5N7969eeONNzCbnf5xZ5fj0sV37tw5Wrduzcsvv0xUVJTRcUQqPZvNRnJyMvHx8SxfvpwHH3yQmJgYHn744UpVICdPnmTgwIEUFhayaNEiLXzhZFy6+ODCp7uuXbuyfft26tevb3QckUrp6NGjzJkzh8TERKpVq0Z0dDQDBw4seeygMrJarUycOJH4+HgWL15Mu3btjI4kZcTliw/gzTffZMWKFdq4VuQGFBQU8OmnnxIfH8+ePXsYMGAAMTExtGrVyuhoZWr58uXExMTwyiuvMHr0aD3y4ARUfFz4ZPfAAw/QtWtXXnjhBaPjiDgsu93Otm3bSEhIYPHixdx7771ER0fz+OOPl3rmztmkpqbSu3dvmjdvzsyZM/H19TU6ktwCFd//pKWlER4ezsqVK7VxrcjvZGVlMW/ePBISEjh//nzJM3eXe5jcWZ07d46RI0eyd+9eli5dSuPGjY2OJDfJZZYsu5aQkBDeffddbVwr8j/FxcV8/vnn9OzZk9DQUA4cOEBcXByHDx/mxRdfdKnSA/D19WXu3LmMGDGCdu3asWzZMqMjyU3SiO93Bg0ahL+/P7GxsUZHETHE/v37iY+PZ8GCBdx5553ExMQQGRlJ1apVjY7mMLZs2ULfvn0ZNmwYr776qu4NqGRUfL9z+vRpWrRowfvvv6+Na8Vl5ObmsnDhQuLj4/n5559Lnrlr0qSJ0dEcVlZWFv369cPb25sFCxZQs2ZNoyPJdVLxXcaGDRvo16+fNq4Vp2az2Vi7di3x8fGsWLGChx9+mJiYGB566CGNYK6TxWJhwoQJJCUlkZSUpPsDKgkV3xVo41pxVj/++COJiYkkJiZSs2ZNoqOjiYqK0ojlFiQlJTFq1CjefPNNYmJijI4j16Diu4Lz58/Trl07hg8fzqhRo4yOI3JLzp07x9KlS0lISGDfvn1ERUURHR1Ny5YtjY7mNA4ePEivXr1o374906dPd+rHOyo7Fd9VpKSk8Mc//pFNmzYRGhpqdByRG2K32/nmm2+Ij48nKSmJtm3bEhMTw2OPPYaX1+V3KZBbc+bMGWJiYjh69ChLly696S2WpHzpcYarCA0NZdKkSQwcOJDz588bHUfkumRmZvLWW2/RrFkzhgwZQsOGDdm3bx8rVqygT58+Kr1y5Ofnx+LFi+nXrx8RERGsXr3a6EhyGRrxXYPdbufxxx/nD3/4gzauFYd1/vx5vvzyS+Lj49m0aRO9evUiOjqa+++/X9eoDbJu3TqioqIYM2YM48ePL7P9BuXWqfiugzauFUe1b9++kn3u7rrrLqKjo+nTp4+euXMQGRkZREZGUqdOHebMmUO1atWMjiRoqvO61K5dm48++oghQ4aQm5trdBxxcadOnSI2NpY2bdrw6KOP4uvry+bNm1m/fj3Dhg1T6TmQoKAg1q9fT1BQEG3atOG7774zOpKgEd8N0ca1YhSr1cqaNWtISEhg5cqVPPLII8TExPDggw/qmbtKYt68eTz77LNMnz6dAQMGGB3Hpan4boA2rpWKduTIERITE5kzZw4BAQElz9zddtttRkeTm7Bnzx569erFY489xtSpU/Hw8DA6kktS8d0gbVwrv3Uiv4iknRmkHM8jr9CCv7eZ0Lr+RLYOombVm7t78uzZsyxdupT4+Hj279/PwIEDiY6OpkWLFmWcXoxw6tQpBg8eTG5uLkuWLCEwMNDoSC5HxXcTtHGt7EnPZUZyKusP5wBQZLGV/Mzb7IYd6NQ0gNEdG9MiuPo1z2e329myZQsJCQkkJSXRrl07YmJi6NGjhx4/cEI2m43JkycTFxfHwoULad++vdGRXIqK7yZo41rXNn/rUSavSKHQYuX3vz35e1eTv/dr6g56C5MJjv6jB/9cvI6xkZ0ue65jx46V7HNnt9tL9rmrV69e+b8RMdxXX33F0KFDefHFFxkzZowePakguqvzJri7uzN37lzefvttdu3aZXQcqUAXSu8gBcWXlt7vXfx57PojzN96tOT758+fZ+nSpfTo0YO7776b77//nvj4eFJSUnjhhRdUei6ka9eubN26lTlz5hAVFUV+fr7RkVyCiu8mXdy4NioqShvXuog96blMXpFCQbHt2i/+jUKLjckrUkhat52//OUvBAUF8d577xEZGUlGRgYfffQR7dq106d9F9WwYUP++9//4uPjQ9u2bTl8+LDRkZyeiu8WDBgwgPDwcMaNG2d0FKkAM5JTKbRYATi9ZQk/xz1B2tuRHJs1inOHNl/12MJiK+Nmf42fnx9btmwhOTmZoUOHUqVKlYqILg7Ox8eH2bNnM2bMGP74xz/y+eefGx3JqZmNDlDZvf/++7Rs2ZLly5dr41ondiK/iPWHc0qmL801Aqkz8E3cq9bgXMomTiz/F/Vuv/JC5nbAq2EYfxnf5abv9hTnZjKZGDFiBC1btiQyMpJvvvmG119/HbNZ/0yXNY34blH16tWZO3cuTz75JFlZWUbHkXKStDOj1NdVQv+I2a8mJpMbVe7qgLlGPc4fu/oUlQlI2pVx1deIREREsGPHDrZv307Xrl3JyckxOpLTUfGVgQ4dOhAdHc3w4cPRTbLOKeV4XqlHFvL3reFY/J9Je6cfae/0ozjnJ6wFeVc9R6HFRkrmmfKOKk4gICCA//znP0RERBAeHs62bduMjuRUVHxl5NVXXyUzM5O4uDijo0g5yCu0lPzZcjqbk1+9x20PPUXwMx8T8tdFeATU58KE5rXOU1yOKcWZuLu7M2XKFN5991169OjBhx9+qA/WZUTFV0Y8PT1ZsGABL7/8MikpKUbHkTLm7/3rdRZbcSFgwt33wkr7+XtXUZzz03WeR0tUyY3505/+xKZNm5g+fTrDhw+noKDA6EiVnoqvDGnjWudTUFDAxx9/zOYVSXj877fFs1YI/hH/x/F548h4bzDnc47iFdTsmufyNrsRGuhXzonFGTVp0oStW7dSUFDA/fffz48//mh0pEpNK7eUMW1cW/nZ7Xa++eYbEhISWLJkCREREUQOiuHNQ36ct9zYM3y/5WV2Y7Pu6pRbYLfbmT59OlOmTCExMZFHH33U6EiVkoqvHFzcuHbhwoV06NDB6DhynS4uH5aYmIjVaiU6OprBgwcTFBQEwIh5O1h1MOuaK7ZcjskEjzSrQ9yg8DJOLa5o48aN9O/fn5EjR/K3v/1Nu7vfIP2/VQ60cW3lUVRUxJIlS+jWrRt33303qampzJ49m0OHDjFhwoSS0gN4ulNjvM03tyi5t9md0Z0al1VscXHt27dnx44drFq1iscff5xTp04ZHalSUfGVk27dutG9e3eefvppo6PI79jtdnbu3Mmf//xngoKCiIuLY8CAAWRkZDBr1qwrLh/WIrg6L3ULxcfjxn5tfDzceKlbKM2Drr1Lg8j1CgwMZO3atTRu3Jjw8HD27NljdKRKQ1Od5Ugb1zqW7OxsFixYQEJCAmfOnGHYsGEMHTqUBg0a3NB5rrY7w2+ZTBdGei91C2VQ2xv7b4jciE8++YQxY8bw9ttvM3jwYKPjODwVXznTxrXGKi4uZsWKFSQkJJCcnEzPnj2Jjo6mQ4cOt3RdZG9GLrHJqaw7lIOJCw+nX3RxP77OTQMY3amxRnpSIb777jt69erFQw89xDvvvIOnp6fRkRyWiq8CaOPairdv3z4SEhJYsGABTZo0ITo6msjISPz8yvZxgpP5RSTtyiAl8wx5hcX4e3sQGuhHn7Cb34Fd5GadPn2aoUOHkpWVxZIlS0pdo5ZfqfgqgNVqpUuXLjz66KPauLYc/fLLL3z88cckJiaSlZXF0KFDGTp0KHfeeafR0UQqjM1m46233mL69OksWLCAzp07Gx3J4aj4KkhaWhrh4eF89dVXhIWFGR3HaVgsFlatWkVCQgJff/01jz76KNHR0TzwwAMaXYtLW716NYMGDWLs2LGMGzdO+z3+hoqvAn3yySdMnDiRXbt24evra3ScSi0lJYXExETmzZtHUFAQ0dHR9O/fn+rVdT1N5KK0tDT69OlDSEgICQkJZT7VX1npcYYKNGDAAFq3bq2Na2/S6dOn+fDDD7nvvvvo3LkzNpuNVatW8c033/DUU0+p9ER+JyQkhA0bNlCzZk0iIiI4ePCg0ZEcgkZ8FSw3N5eWLVsyY8YMunfvbnQch2ez2Vi7di2JiYksX76cBx98kGHDhtG1a1dt0ClyA+Lj4xk/fjyxsbFERkYaHcdQKj4DbNiwgf79+7N7925q165tdByH9MMPP5CYmMicOXOoWbMmw4YNIyoqilq1ahkdTaTS2rVrF71796Z379688cYbLvvhUcVnkAkTJrBv3z6WLVumi87/k5+fT1JSEgkJCRw8eJCoqCiio6Np0aKF0dFEnMbJkycZOHAghYWFLFq0iDp16hgdqcLpGp9BJk6cSGZmJjNnzjQ6iqHsdjsbNmwgOjqa4OBgPv30U/7yl7+QkZHBtGnTVHoiZaxmzZp8+eWXdOjQgdatW7N582ajI1U4jfgMlJKSQvv27dm4cSOhoaFGx6lQaWlpzJ07l8TERLy9vYmOjmbgwIHUrVvX6GgiLmP58uXExMTw97//naefftplZp9UfAaLi4tj1qxZbNmyxemXGCooKOCzzz4jISGBXbt20a9fP6KjowkPD3eZXzgRR3PkyBF69epF8+bNmTlzpks8aqWpToONHDmSevXq8corrxgdpVzY7Xa2bt3KyJEjuf322+Ojm2kAABKeSURBVJk7dy5PPPEEP//8M7GxsbRp00alJ2KgRo0asWXLFgDuu+8+UlNTAfjxxx/59ttvjYxWbjTicwDOuHHttTZ1FRHHYrfbiY2NZeLEiUyfPr3keeOffvrJ6VZBUvE5iC+//JKnn36a3bt3V9oHsYuKili2bBkJCQls2bKF3r17M2zYsCvubycijmfz5s106dIFi8WCj48P8fHxl33u70R+EUk7M0g5nkdeoQV/bzOhdf2JbO34C7Sr+BzI6NGjOX36NAsWLDA6ynWz2+18++23JCQksHDhQu655x6io6Pp1asXVapUMTqeiNygSZMmMWnSJIqKigC44447SE1NLfnwuic9lxnJqaw/nANA0WW25OrUNIDRHRvTItgxP8TrGp8D+ec//8muXbv4+OOPjY5yTTk5Obzzzju0aNGC3r17U6tWLbZv387atWsZPHiwSk+kksrOzqZKlSp4eXnh6enJDz/8wOzZs4ELmzD3n7WVVQezKLLYSpUeXNiXsshi4+sDWfSftZX5W48a8A6uTSM+B+PIG9de3NQ1MTGRdevW0bNnT4YNG0bHjh1vaVNXEXE8WVlZ7Ny5k3nz5tG1a1fcm3Zk8oqDFBTbsORm8XPccEKe/wKT25Wv//l4uPFSt7sY1LZBxQW/Dio+B/TGG2+wcuVKh9m49rvvvivZ1PXOO+9k2LBhREZG4u/vb3Q0EakAe9Jz6T9rKwXFVoBLiu/swY2c2fEF57N+xDPwTuoOfKPkWHvmQXKWvIrbby7znz17lqSkJHr37l3RbwXQVKdDeu6554ALU59G+eWXX5gxYwbh4eF07doVb29vNm7cyMaNGxk+fLhKT8SFzEhOpdBiveLP3Xz88AvviX/bPpf+rN5dDJmZTH5+Pvn5+SxfvpyqVavStWvX8ox8Va65QqmDc3d3Z968eYSHh/PQQw9V2Ma1VquVr7/+utSmrlOmTNGmriIuJD09nWeeeYaNGzdis9n4U5++bKzVnV/WxJO/bw1unj74R/xfqWN8GrQE4Mye/1xyPrsd1h3K4WR+ETWrejFnzhz69Olj6H0AKj4HFRISwrRp04iKiirZuLa8bh8+dOgQiYmJzJ07l6CgIIYNG8bMmTOpUaNGGb4jEXF0VquVHj160KVLF+bNm4e7uzt/m/UFp1d+xbnU7QRGv4vJw5ucz6bc0HlNQNKuDAa1rktSUhLLli0rnzdwnVR8DiwqKooVK1Yw8b1ETtWLuMLtw8d5Z/Xhq94+fOzYMXbu3Mljjz1W8r28vDwWLVpEQkICP/74I4MGDeLrr7/m7rvvLv83JiIOadu2bRw7doypU6eWbFlkqd2E0/un4N/mccz+AQBUuy+S7LR9133eQouNlMwzfPrpZmrVqkXHjh3LJf/1UvE5uIdHv86Ur1IoOpjF5W5DKvxfCX59IIsNh0/wUrfQUndQnTx5knbt2pGVlUV2djbbtm0jISGB5cuX88ADD/Diiy9qU1cRAS5Mc9avX7/Uvwd5hRas+b/g7hdQ8j2z/43vI5pXWMyceXMYMmSI4Qta6F87BzZ/61H+8VUKhcW2q74ud+MCLLmZ1HpsHJNXHARgUNsG5Ofn06lTJ44dO4bJZKJhw4YEBwcTHR3NtGnTtKmriJQSHBxMWloaFoulpPz8vc24V62B9UxOyesseTlXOsUVmfJPkpyc7BBbsan4HFS94BDMHUfhFtz8ho4rKLYxeUUKTQN8iOr6R44cOcLFJ1bq1KnjtIvOisiti4iIIDAwkBdeeIGJEyfi7u6OR873VLu7A6e2/RufRhGYPL3J27qk1HF2mxUu/s9ux245DyY3TO4XKsbb7MaJ3ato164djRo1MuKtlaLHGRzUmUIL561XH+ldSaHFypvL95CdnY23tzdubm54e3tz4MABTp48WcZJRcRZuLu7s2zZMlJTUwkJCSEoKIjc/eup1qor3g3DyIz/M5kJz+DbpF2p485+t460f/bil//EUpSxn7R/9uLkyvdKfm4H9q9fztChQyv4HV2eHmB3QH0HRLFk4UJMZg8wuVHt/v7kJidSs/tfyd04H3txEf5telKtXT+g9FSn3WrhxPK3cbNbOPzfrwi8zY/i4mKysrI4deoUf/jDHwyfXxeRymXEvB2susJ9BtdiMsEjzeoQNyi87IPdJI34HFCXp17HXC2AgD5/J2RsElVC2wNQlLGfek/GUaf/JHL/+wnFJ9JLHWcrLiLn00mY3D2o12sC//4uGwAPDw+CgoK45557VHoicsOe7tQYb/PNPcvrbXZndKfGZZzo1qj4HFDK8bzLfrKqdn8Ubh5eeNa5A8/aDTmf/UPJz2xF58he/Arm6oHU7P4XimwmUjLPVGBqEXFWLYKr81K3UHw8bqwyLqzVGUrzIMfapUHF54DyCi2X/b571V8fKDeZvbAVF5Z8XXTsEMXZP+Lftk/JqC6vsLh8g4qIyxjUtgEvdbsLHw93rjVxZDKBj4e7Qy5QDSo+h+Tvbeaaf7N+x6dhK/zviyRr4UtYz57633k8yiOeiLioQW0bsGhEWx5pVgcvsxve5tIV4m12w8vsxiPN6rBoRFuHLD3Q4wwOKbSuPx5Vq2PJPX5Dx1Vr2we7tZisT14iZMibhAb6lVNCEXFVzYOqEzconJP5RSTtyiAl8wx5hcX4e3sQGuhHnzDH34FdxeeA+rQO4vV2fcn6Txyn1iWU3L15ParfPwC71ULGgpd44JlN5ZhSRFxZzapejOxg/DN5N0OPMzgoZ7t9WETEUegan4NyttuHRUQchYrPQTnb7cMiIo5C1/gc2MU7oiavSKHQYr3qtKcJsFvO8/DtNoe9k0pExBHoGl8lsDcjl9jkVNYdysHEr1sRwYXbh+1A56YBdKlr4f9FPc4333xDw4YNDcsrIuLIVHyVyPXcPvzOO++wePFiNmzYgIeHnuMTEfk9FZ+Tsdls9OjRg5YtWzJlyhSj44iIOBwVnxPKzs6mVatWzJ07lwceeMDoOCIiDkV3dTqh2rVrk5iYyNChQ8nJufGdkkVEnJlGfE5s/Pjx7N+/n2XLlmk7IhGR/9GIz4m9/vrrZGdn89577137xSIiLkIjPid35MgR2rZty6pVq2jZsqXRcUREDKcRn5Nr1KgR06ZNo3///pw9e9boOCIihtOIz0UMGzYMs9nMRx99ZHQUERFDacTnIt577z02bNjAokWLjI4iImIojfhcyM6dO3n00Ue1pJmIuDSN+FxI69ateeGFF4iKiqK4uNjoOCIihtCIz8XYbDa6d+9OWFgYkydPNjqOiEiFU/G5oKysLFq1asX8+fPp0qWL0XFERCqUpjpdUJ06dUhMTGTIkCGcOHHC6DgiIhVKIz4X9vzzz3Pw4EH+/e9/a0kzEXEZGvG5sEmTJpGVlcX7779vdBQRkQqjEZ+Lu7ik2erVq2nRooXRcUREyp1GfC5OS5qJiKvRiE8AGDp0KJ6ensyaNcvoKCIi5UojPgHg/fffJzk5WUuaiYjT04hPSmhJMxFxBRrxSYnWrVszfvx4LWkmIk5NIz4pxWaz0a1bN8LDw5k0aZLRcUREypyKTy5xcUmzBQsW0LlzZ6PjiIiUKU11yiW0pJmIODON+OSKnn/+eVJSUvjiiy+0pJmIOA2N+OSKJk2aRGZmJjNmzDA6iohImdGIT64qNTWV++67T0uaiYjT0IhPrqpx48a88847WtJMRJyGRnxyXYYMGYKXl5eWNBORSk8jPrkuM2bMIDk5mcWLFxsdRUTklmjEJ9dtx44ddOvWjW3bttGgQQOj44iI3BSN+OS6hYeH8/zzzxMVFYXFYjE6jojITVHxyQ159tln8ff3Z+LEiUZHERG5KZrqlBt2cUmzjz/+mE6dOhkdR0TkhmjEJzesTp06JCQkMHjwYC1pJiKVjkZ8ctOee+45Dh8+zOeff64lzUSk0tCIT27a5MmT+fnnn4mNjTU6iojIddOIT27J999/T7t27bSkmYhUGhrxyS258847efvtt7WkmYhUGhrxSZkYPHgwPj4+fPjhh0ZHERG5Ko34pEzExsaybt06lixZYnQUEZGr0ohPyszFJc22b99O/fr1jY4jInJZGvFJmdGSZiJSGaj4pEw9++yzVK1alddee83oKCIil6WpTilzx48fJywsTEuaiYhD0ohPylzdunWJj49n8ODBnDx50ug4IiKlaMQn5WbcuHGkpqby2WefaUkzEXEYGvFJuZkyZQoZGRla0kxEHIpGfFKuLi5ptmbNGpo3b250HBERjfikfN15553861//on///pw7d87oOCIiGvFJxRg8eDC+vr7MnDnT6Cgi4uI04pMKMWPGDNasWUNSUpLRUUTExWnEJxVm+/btdO/eXUuaiYihNOKTCtOmTRuee+45Bg4cqCXNRMQwKj6pUGPHjsXX15fXX3/d6Cgi4qI01SkV7vjx47Rq1YqFCxfSsWNHo+OIiIvRiE8qnJY0ExEjacQnhhk7dixHjhzRkmYiUqE04hPDTJkyhfT0dD744AOjo4iIC9GITwx1cUmztWvXcs899xgdR0RcgEZ8YigtaSYiFU0jPjGc3W5n8ODBVK1albi4OKPjiIiT04hPDGcymYiNjWX16tUsXbrU6Dgi4uQ04hOHsW3bNh577DG2b99OSEiI0XFExElpxCcOIyIigrFjx2pJMxEpVyo+cSjjxo3D29ubSZMmGR1FRJyUpjrF4WRmZhIWFqYlzUSkXGjEJw4nMDBQS5qJSLlR8YlDevTRR4mMjGT48OF89NFHBAYGkp+fb3QsEXECmuoUh5WdnU2TJk0oKCjA3d2d9evX06ZNG6NjiUglpxGfOKRTp07RokULzp07x/nz5wHYv3+/walExBmo+MQh+fv7M2TIEMxmM2azmYKCAnbs2GF0LBFxAprqFIeWk5PDxIkTiY2NJSgoiLS0NABO5BeRtDODlON55BVa8Pc2E1rXn8jWQdSs6mVwahFxZCo+qRQOHz7Mli1baNmlJzOSU1l/OAeAIout5DXeZjfsQKemAYzu2JgWwdUNSisijkzFJ5XG/K1HmbwihUKLlav9rTWZwNvszkvdQhnUtkGF5RORykHX+KRSuFB6BykovlB6ltwsfnqjB3ab9ZLX2u1QUGxl8oqDzN96tOLDiohDU/GJw9uTnsvkFSkUFNuu+VprwRnS343i+PznKSi2MXlFCrOXLCcoKKgCkopIZaDiE4c3IzmVQsulI7vLyU1OwKNmcMnXhRYrX+z+ubyiiUglZDY6gMjvpaen88wzz7Bx40asVhu2Ru2o1uVJcpMTyd+3BjdPH/wj/u+S4wozDnI+5yf8WnYlf+8qAKxFhSyfPgasxVStWhW4cKNMvXr1KvQ9iYjj0IhPHIrVaqVHjx7Ur1+fo0ePMnHhRvybdSR/z384l7qdwOh3qTtsGmcP/bfUcXablVOr4rjt4VGAqeT7bp7eBPV/jWq1apOfn09+fr5KT8TFqfjEoWzbto1jx44xdepUqlSpwpFTRbjVu4uzBzfh3+ZxzP4BuPv4Ue2+yFLHndmxDM96TfCq2/iSc5632rBYdfOyiFyg4hOHkp6eTv369TGbL8zC5xVe2JDWmv8L7n4BJa8z+9cu+bPlzEnydi6jeochVzyvTb0nIv+ja3ziUIKDg0lLS8NisWA2m/H3vvBX1L1qDaxnckpeZ8n79c/nMw9jzf+FYx+NAsBuOY+9+Dzp7w0i6Ok5YDLhZkJEBFDxiYOJiIggMDCQF154gYkTJ9Kohhe2zINUCW3PmR3L8GkUgcnTm7ytS0qO8bkjnKBR8SVfnz24gbMH1lO798uY3Nzx8b+NX/JPc/r0aapVq2bE2xIRB6LiE4fi7u7OsmXLGDNmDCEhIYAJW6P78e88nOJffiYz/s+YvHypFvF/FP60FwCT2QP3qjVKzuHmVQWTu7nke561gons24877rgDq9XKgQMHdIOLiAvTkmXi8EbM28Gqg1lXXabsSkwmeKRZHeIGhZd9MBGplHRzizi8pzs1xtvsflPHepvdGd3p0js9RcR1qfjE4bUIrs5L3ULx8bixv64+Hm681C2U5kHapUFEfqVrfFIpXNxlQbsziMit0jU+qVT2ZuQSm5zKukM5mIDCy+zH17lpAKM7NdZIT0QuS8UnldLJ/CKSdmWQknmGvMJi/L09CA30o0+YdmAXkatT8YmIiEvRzS0iIuJSVHwiIuJSVHwiIuJSVHwiIuJSVHwiIuJSVHwiIuJSVHwiIuJSVHwiIuJSVHwiIuJSVHwiIuJSVHwiIuJSVHwiIuJSVHwiIuJSVHwiIuJSVHwiIuJSVHwiIuJSVHwiIuJSVHwiIuJSVHwiIuJSVHwiIuJSVHwiIuJS/j9cbDQx0uCEfgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hc.init_node_memory_object('all')"
      ],
      "metadata": {
        "id": "SKkRYOES9J94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for node in hc.graph.nodes:\n",
        "  hc.init_node_memory_object(node)"
      ],
      "metadata": {
        "id": "9R9sIU7P8ZRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hc.graph.nodes.data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inP3XhbR-vvk",
        "outputId": "28ac1ed6-cc08-4fef-ba66-81159f9fe80a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NodeDataView({'all': {'memory': <__main__.Node_Memory object at 0x7f0f47fb76d0>}, 'tnk': {'memory': <__main__.Node_Memory object at 0x7f0f47e58e50>}, 'cd4t': {'memory': <__main__.Node_Memory object at 0x7f0f47e58990>}, 'cd8t': {'memory': <__main__.Node_Memory object at 0x7f0f47e58450>}, 'm': {'memory': <__main__.Node_Memory object at 0x7f0f47e58a90>}, 'cd17': {'memory': <__main__.Node_Memory object at 0x7f0f47e58410>}, 'fc': {'memory': <__main__.Node_Memory object at 0x7f0f47e58610>}})"
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Syntax erlaubt zugriff auf attribute des memory ojekts von node 'all'\n",
        "hc.graph.nodes['all']['memory'].prediction_vec"
      ],
      "metadata": {
        "id": "UB8sxowZJj50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_vec = ['tnk', 'm', 'm', 'm', 'tnk','tnk', 'm', 'tnk']"
      ],
      "metadata": {
        "id": "uFr5roSATlVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_vec"
      ],
      "metadata": {
        "id": "9bCBbPuTTm75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test der Hierarchical_Classifier.subset_pred_vec Methode \n",
        "\n",
        "\n",
        "#assign made up pred vec to node 'all'\n",
        "hc.graph.nodes['all']['memory'].prediction_vec = ['tnk', 'm', 'm', 'm', 'tnk','tnk', 'm', 'tnk']\n",
        "\n",
        "#assign made up input data to 'all' node, from which daughter nodes will be subsetting \n",
        "hc.graph.nodes['all']['memory'].x_input_data = [[0,0,0], [1,1,1], [2,2,2], [3,3,3], [4,4,4], [5,5,5], [6,6,6], [7,7,7]]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cYD1deKLky4",
        "outputId": "b3110c50-c4b3-4df5-fb20-c235bb91ee46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['tnk', 'm', 'm', 'm', 'tnk', 'tnk', 'm', 'tnk']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.array(hc.graph.nodes['all']['memory'].prediction_vec))\n",
        "\n",
        "next_labels = [label for label in hc.graph['all'].keys()]\n",
        "print(next_labels[0])\n",
        "idx_vec = np.where(np.array(hc.graph.nodes['all']['memory'].prediction_vec) == next_labels[0])\n",
        "print(idx_vec)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOat4ayRQ8lK",
        "outputId": "529a256c-c5ee-4589-fd05-542aff1cf6bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['tnk' 'm' 'm' 'm' 'tnk' 'tnk' 'm' 'tnk']\n",
            "tnk\n",
            "(array([0, 4, 5, 7]),)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "hc.subset_pred_vec('all')"
      ],
      "metadata": {
        "id": "VwQuuPSVQ5vS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ausgabe der subsetted input vektoren der nachfolgenden knoten \n",
        "# print(f'generierte x_input_data für tnk node: {hc.graph.nodes['tnk']['memory'].x_input_data}')\n",
        "# print(f'generierte x_input_data für m node: {hc.graph.nodes['m']['memory'].x_input_data}')\n",
        "\n",
        "print(hc.graph.nodes['tnk']['memory'].x_input_data)\n",
        "print(hc.graph.nodes['m']['memory'].x_input_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ASRXtwoNFK-",
        "outputId": "40967062-4516-4c25-a3b7-b2ab418f7491"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(hc.subset_pred_vec('tnk'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mo32shJKFSSK",
        "outputId": "cd9457c7-9575-44b5-b362-d1527c24927f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['cd4t', 'cd8t']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nx.draw(hc.graph, with_labels=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "PSmNY8gdb2yd",
        "outputId": "91a3f11c-9cff-44d2-cf1f-0763fe2e2792"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test of Local classifier class**"
      ],
      "metadata": {
        "id": "F_RdxaiARRj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yExXmrwfQuPx",
        "outputId": "48f93d4c-f23e-4f77-f0cb-239b00b722dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scanpy \n"
      ],
      "metadata": {
        "id": "ICWY1MyZRVbk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24bda604-fb4b-4384-bcbd-74be97fd3e7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scanpy\n",
            "  Downloading scanpy-1.8.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 7.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from scanpy) (0.11.2)\n",
            "Requirement already satisfied: scipy>=1.4 in /usr/local/lib/python3.7/dist-packages (from scanpy) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from scanpy) (1.0.2)\n",
            "Requirement already satisfied: patsy in /usr/local/lib/python3.7/dist-packages (from scanpy) (0.5.2)\n",
            "Requirement already satisfied: tables in /usr/local/lib/python3.7/dist-packages (from scanpy) (3.7.0)\n",
            "Requirement already satisfied: importlib_metadata>=0.7 in /usr/local/lib/python3.7/dist-packages (from scanpy) (4.11.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from scanpy) (1.1.0)\n",
            "Collecting sinfo\n",
            "  Downloading sinfo-0.3.4.tar.gz (24 kB)\n",
            "Requirement already satisfied: networkx>=2.3 in /usr/local/lib/python3.7/dist-packages (from scanpy) (2.6.3)\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.7/dist-packages (from scanpy) (5.5.0)\n",
            "Collecting umap-learn>=0.3.10\n",
            "  Downloading umap-learn-0.5.2.tar.gz (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from scanpy) (21.3)\n",
            "Collecting anndata>=0.7.4\n",
            "  Downloading anndata-0.8.0-py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: statsmodels>=0.10.0rc2 in /usr/local/lib/python3.7/dist-packages (from scanpy) (0.10.2)\n",
            "Requirement already satisfied: h5py>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from scanpy) (3.1.0)\n",
            "Requirement already satisfied: numba>=0.41.0 in /usr/local/lib/python3.7/dist-packages (from scanpy) (0.51.2)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from scanpy) (1.21.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from scanpy) (4.63.0)\n",
            "Requirement already satisfied: matplotlib>=3.1.2 in /usr/local/lib/python3.7/dist-packages (from scanpy) (3.2.2)\n",
            "Requirement already satisfied: pandas>=0.21 in /usr/local/lib/python3.7/dist-packages (from scanpy) (1.3.5)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.7/dist-packages (from anndata>=0.7.4->scanpy) (3.10.0.2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.10.0->scanpy) (1.5.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib_metadata>=0.7->scanpy) (3.7.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.2->scanpy) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.2->scanpy) (3.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.2->scanpy) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.2->scanpy) (2.8.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.41.0->scanpy) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.41.0->scanpy) (0.34.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21->scanpy) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=3.1.2->scanpy) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->scanpy) (3.1.0)\n",
            "Collecting pynndescent>=0.5\n",
            "  Downloading pynndescent-0.5.6.tar.gz (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 47.1 MB/s \n",
            "\u001b[?25hCollecting stdlib_list\n",
            "  Downloading stdlib_list-0.8.0-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numexpr>=2.6.2 in /usr/local/lib/python3.7/dist-packages (from tables->scanpy) (2.8.1)\n",
            "Building wheels for collected packages: umap-learn, pynndescent, sinfo\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.2-py3-none-any.whl size=82708 sha256=47f201506fe5495f56bf8599397ee12873da85441f673c64ea6b2d9c7d8b5603\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/1b/c6/aaf68a748122632967cef4dffef68224eb16798b6793257d82\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.6-py3-none-any.whl size=53943 sha256=e25d3a2e521d7dfd912f9f1defff5964b21cc9490731b9ef07099522a04a42be\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/f1/56/f80d72741e400345b5a5b50ec3d929aca581bf45e0225d5c50\n",
            "  Building wheel for sinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sinfo: filename=sinfo-0.3.4-py3-none-any.whl size=7899 sha256=c98ee6d9ed9dc6099aed94e28edda1598630af7b72626d88cbccd4fa5bc3e7e0\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/ca/56/344d532fe53e855ccd6549795d370588ab8123907eecf4cf30\n",
            "Successfully built umap-learn pynndescent sinfo\n",
            "Installing collected packages: stdlib-list, pynndescent, umap-learn, sinfo, anndata, scanpy\n",
            "Successfully installed anndata-0.8.0 pynndescent-0.5.6 scanpy-1.8.2 sinfo-0.3.4 stdlib-list-0.8.0 umap-learn-0.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scanpy as sc"
      ],
      "metadata": {
        "id": "qvbTHN7Tek7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adata = sc.read('drive/MyDrive/single_cell/processed/pbmc3k_level_1_scvi.h5ad')\n",
        "\n",
        "X_input, y_input = adata.obsm['X_scVI'], adata.obs['training_level_1']\n",
        "\n",
        "# print(f'y_input: {y_input}' )\n",
        "\n",
        "# print(f'\\n\\n*******************\\n {len(y_input.cat.categories)}')\n",
        "\n",
        "nn_tnk = Neural_Network(X_input, y_input, epochs = 200)\n",
        "\n",
        "nn_tnk.model.summary()\n",
        "\n",
        "# nn_tnk.local_classifier_output()\n",
        "nn_tnk.process_input_data()\n",
        "nn_tnk.train()\n",
        "\n",
        "# nn_tnk.predict(nn_tnk.x_training_input)\n",
        "\n",
        "nn_tnk.validate()\n",
        "\n",
        "print(f'training_acc: {nn_tnk.train_acc:42f}')\n",
        "\n",
        "print(f'test_acc: {nn_tnk.test_acc:.4f}')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MIoF8UQJRf9g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc80e36d-90af-4838-9b44-6b9fe183c6f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 30)                330       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 124       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 454\n",
            "Trainable params: 454\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "25/25 [==============================] - 1s 9ms/step - loss: 1.5349 - val_loss: 1.3964\n",
            "Epoch 2/200\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 1.2436 - val_loss: 1.1240\n",
            "Epoch 3/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 1.0263 - val_loss: 0.9539\n",
            "Epoch 4/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.8885 - val_loss: 0.8460\n",
            "Epoch 5/200\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.7951 - val_loss: 0.7711\n",
            "Epoch 6/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.7255 - val_loss: 0.7138\n",
            "Epoch 7/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.6701 - val_loss: 0.6655\n",
            "Epoch 8/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.6228 - val_loss: 0.6246\n",
            "Epoch 9/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.5819 - val_loss: 0.5892\n",
            "Epoch 10/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.5458 - val_loss: 0.5581\n",
            "Epoch 11/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.5141 - val_loss: 0.5299\n",
            "Epoch 12/200\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4856 - val_loss: 0.5053\n",
            "Epoch 13/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.4604 - val_loss: 0.4832\n",
            "Epoch 14/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.4377 - val_loss: 0.4634\n",
            "Epoch 15/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.4175 - val_loss: 0.4455\n",
            "Epoch 16/200\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3993 - val_loss: 0.4301\n",
            "Epoch 17/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3827 - val_loss: 0.4161\n",
            "Epoch 18/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3680 - val_loss: 0.4031\n",
            "Epoch 19/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3548 - val_loss: 0.3915\n",
            "Epoch 20/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3425 - val_loss: 0.3811\n",
            "Epoch 21/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3316 - val_loss: 0.3716\n",
            "Epoch 22/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3216 - val_loss: 0.3629\n",
            "Epoch 23/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3125 - val_loss: 0.3550\n",
            "Epoch 24/200\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3042 - val_loss: 0.3476\n",
            "Epoch 25/200\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.2966 - val_loss: 0.3414\n",
            "Epoch 26/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.2895 - val_loss: 0.3351\n",
            "Epoch 27/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.2829 - val_loss: 0.3294\n",
            "Epoch 28/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.2769 - val_loss: 0.3241\n",
            "Epoch 29/200\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.2713 - val_loss: 0.3194\n",
            "Epoch 30/200\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.2659 - val_loss: 0.3146\n",
            "Epoch 31/200\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.2610 - val_loss: 0.3102\n",
            "Epoch 32/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.2563 - val_loss: 0.3061\n",
            "Epoch 33/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.2520 - val_loss: 0.3019\n",
            "Epoch 34/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.2479 - val_loss: 0.2988\n",
            "Epoch 35/200\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.2439 - val_loss: 0.2955\n",
            "Epoch 36/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2402 - val_loss: 0.2918\n",
            "Epoch 37/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.2367 - val_loss: 0.2888\n",
            "Epoch 38/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.2334 - val_loss: 0.2861\n",
            "Epoch 39/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.2301 - val_loss: 0.2830\n",
            "Epoch 40/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2271 - val_loss: 0.2801\n",
            "Epoch 41/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.2242 - val_loss: 0.2773\n",
            "Epoch 42/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.2214 - val_loss: 0.2750\n",
            "Epoch 43/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.2189 - val_loss: 0.2721\n",
            "Epoch 44/200\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.2162 - val_loss: 0.2702\n",
            "Epoch 45/200\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.2138 - val_loss: 0.2682\n",
            "Epoch 46/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.2114 - val_loss: 0.2660\n",
            "Epoch 47/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2092 - val_loss: 0.2636\n",
            "Epoch 48/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.2070 - val_loss: 0.2615\n",
            "Epoch 49/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2049 - val_loss: 0.2594\n",
            "Epoch 50/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.2029 - val_loss: 0.2577\n",
            "Epoch 51/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.2009 - val_loss: 0.2555\n",
            "Epoch 52/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.1990 - val_loss: 0.2536\n",
            "Epoch 53/200\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1971 - val_loss: 0.2518\n",
            "Epoch 54/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.1953 - val_loss: 0.2504\n",
            "Epoch 55/200\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1937 - val_loss: 0.2489\n",
            "Epoch 56/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1918 - val_loss: 0.2469\n",
            "Epoch 57/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.1902 - val_loss: 0.2454\n",
            "Epoch 58/200\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1886 - val_loss: 0.2436\n",
            "Epoch 59/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.1871 - val_loss: 0.2420\n",
            "Epoch 60/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.1855 - val_loss: 0.2405\n",
            "Epoch 61/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.1841 - val_loss: 0.2390\n",
            "Epoch 62/200\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1827 - val_loss: 0.2375\n",
            "Epoch 63/200\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1812 - val_loss: 0.2361\n",
            "Epoch 64/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.1799 - val_loss: 0.2347\n",
            "Epoch 65/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.1785 - val_loss: 0.2332\n",
            "Epoch 66/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.1772 - val_loss: 0.2321\n",
            "Epoch 67/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.1759 - val_loss: 0.2307\n",
            "Epoch 68/200\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1747 - val_loss: 0.2291\n",
            "Epoch 69/200\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1734 - val_loss: 0.2280\n",
            "Epoch 70/200\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1722 - val_loss: 0.2270\n",
            "Epoch 71/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.1710 - val_loss: 0.2254\n",
            "Epoch 72/200\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1698 - val_loss: 0.2243\n",
            "Epoch 73/200\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1686 - val_loss: 0.2228\n",
            "Epoch 74/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.1675 - val_loss: 0.2214\n",
            "Epoch 75/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.1664 - val_loss: 0.2202\n",
            "Epoch 76/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.1654 - val_loss: 0.2188\n",
            "Epoch 77/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1643 - val_loss: 0.2179\n",
            "Epoch 78/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.1632 - val_loss: 0.2168\n",
            "Epoch 79/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.1622 - val_loss: 0.2154\n",
            "Epoch 80/200\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1612 - val_loss: 0.2144\n",
            "Epoch 81/200\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1603 - val_loss: 0.2134\n",
            "Epoch 82/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.1592 - val_loss: 0.2121\n",
            "Epoch 83/200\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1583 - val_loss: 0.2110\n",
            "Epoch 84/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.1574 - val_loss: 0.2098\n",
            "Epoch 85/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.1565 - val_loss: 0.2086\n",
            "Epoch 86/200\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1556 - val_loss: 0.2077\n",
            "Epoch 87/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.1547 - val_loss: 0.2068\n",
            "Epoch 88/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.1538 - val_loss: 0.2055\n",
            "Epoch 89/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1529 - val_loss: 0.2045\n",
            "Epoch 90/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1521 - val_loss: 0.2036\n",
            "Epoch 91/200\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1512 - val_loss: 0.2026\n",
            "Epoch 92/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.1504 - val_loss: 0.2017\n",
            "Epoch 93/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.1496 - val_loss: 0.2008\n",
            "Epoch 94/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.1488 - val_loss: 0.1998\n",
            "Epoch 95/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1480 - val_loss: 0.1990\n",
            "Epoch 96/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.1472 - val_loss: 0.1980\n",
            "Epoch 97/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1464 - val_loss: 0.1968\n",
            "Epoch 98/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1457 - val_loss: 0.1960\n",
            "Epoch 99/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1449 - val_loss: 0.1951\n",
            "Epoch 100/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1443 - val_loss: 0.1942\n",
            "Epoch 101/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1435 - val_loss: 0.1933\n",
            "Epoch 102/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1428 - val_loss: 0.1923\n",
            "Epoch 103/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.1420 - val_loss: 0.1915\n",
            "Epoch 104/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.1413 - val_loss: 0.1907\n",
            "Epoch 105/200\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1407 - val_loss: 0.1899\n",
            "Epoch 106/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.1401 - val_loss: 0.1888\n",
            "Epoch 107/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.1393 - val_loss: 0.1881\n",
            "Epoch 108/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.1387 - val_loss: 0.1873\n",
            "Epoch 109/200\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1381 - val_loss: 0.1866\n",
            "Epoch 110/200\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1374 - val_loss: 0.1856\n",
            "Epoch 111/200\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1368 - val_loss: 0.1851\n",
            "Epoch 112/200\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1362 - val_loss: 0.1843\n",
            "Epoch 113/200\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1356 - val_loss: 0.1834\n",
            "Epoch 114/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1349 - val_loss: 0.1825\n",
            "Epoch 115/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1343 - val_loss: 0.1818\n",
            "Epoch 116/200\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1337 - val_loss: 0.1810\n",
            "Epoch 117/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.1332 - val_loss: 0.1805\n",
            "Epoch 118/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.1326 - val_loss: 0.1796\n",
            "Epoch 119/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1319 - val_loss: 0.1787\n",
            "Epoch 120/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.1314 - val_loss: 0.1782\n",
            "Epoch 121/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.1308 - val_loss: 0.1773\n",
            "Epoch 122/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.1303 - val_loss: 0.1766\n",
            "Epoch 123/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.1297 - val_loss: 0.1761\n",
            "Epoch 124/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.1291 - val_loss: 0.1753\n",
            "Epoch 125/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1286 - val_loss: 0.1745\n",
            "Epoch 126/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1280 - val_loss: 0.1739\n",
            "Epoch 127/200\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1275 - val_loss: 0.1732\n",
            "Epoch 128/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.1270 - val_loss: 0.1726\n",
            "Epoch 129/200\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1264 - val_loss: 0.1719\n",
            "Epoch 130/200\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1259 - val_loss: 0.1713\n",
            "Epoch 131/200\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1254 - val_loss: 0.1705\n",
            "Epoch 132/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.1249 - val_loss: 0.1699\n",
            "Epoch 133/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.1244 - val_loss: 0.1691\n",
            "Epoch 134/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1239 - val_loss: 0.1685\n",
            "Epoch 135/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.1234 - val_loss: 0.1677\n",
            "Epoch 136/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.1229 - val_loss: 0.1671\n",
            "Epoch 137/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.1224 - val_loss: 0.1664\n",
            "Epoch 138/200\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.1220 - val_loss: 0.1659\n",
            "Epoch 139/200\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1215 - val_loss: 0.1653\n",
            "Epoch 140/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.1210 - val_loss: 0.1647\n",
            "Epoch 141/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.1205 - val_loss: 0.1641\n",
            "Epoch 142/200\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1201 - val_loss: 0.1635\n",
            "Epoch 143/200\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1197 - val_loss: 0.1629\n",
            "Epoch 144/200\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1193 - val_loss: 0.1622\n",
            "Epoch 145/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.1188 - val_loss: 0.1617\n",
            "Epoch 146/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1183 - val_loss: 0.1612\n",
            "Epoch 147/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.1179 - val_loss: 0.1606\n",
            "Epoch 148/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.1175 - val_loss: 0.1601\n",
            "Epoch 149/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1172 - val_loss: 0.1594\n",
            "Epoch 150/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1166 - val_loss: 0.1590\n",
            "Epoch 151/200\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1162 - val_loss: 0.1585\n",
            "Epoch 152/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.1158 - val_loss: 0.1579\n",
            "Epoch 153/200\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1154 - val_loss: 0.1573\n",
            "Epoch 154/200\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1150 - val_loss: 0.1568\n",
            "Epoch 155/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.1146 - val_loss: 0.1563\n",
            "Epoch 156/200\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1142 - val_loss: 0.1558\n",
            "Epoch 157/200\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.1138 - val_loss: 0.1553\n",
            "Epoch 158/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.1134 - val_loss: 0.1550\n",
            "Epoch 159/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.1130 - val_loss: 0.1544\n",
            "Epoch 160/200\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.1126 - val_loss: 0.1538\n",
            "Epoch 161/200\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1122 - val_loss: 0.1533\n",
            "Epoch 162/200\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1119 - val_loss: 0.1528\n",
            "Epoch 163/200\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1115 - val_loss: 0.1523\n",
            "Epoch 164/200\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1111 - val_loss: 0.1517\n",
            "Epoch 165/200\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1107 - val_loss: 0.1513\n",
            "Epoch 166/200\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1104 - val_loss: 0.1509\n",
            "Epoch 167/200\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1100 - val_loss: 0.1504\n",
            "Epoch 168/200\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1097 - val_loss: 0.1500\n",
            "Epoch 169/200\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1093 - val_loss: 0.1494\n",
            "Epoch 170/200\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1089 - val_loss: 0.1491\n",
            "Epoch 171/200\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1086 - val_loss: 0.1487\n",
            "Epoch 172/200\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1082 - val_loss: 0.1482\n",
            "Epoch 173/200\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1080 - val_loss: 0.1478\n",
            "Epoch 174/200\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1076 - val_loss: 0.1472\n",
            "Epoch 175/200\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1072 - val_loss: 0.1468\n",
            "Epoch 176/200\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1069 - val_loss: 0.1464\n",
            "Epoch 177/200\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1066 - val_loss: 0.1461\n",
            "Epoch 178/200\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1062 - val_loss: 0.1456\n",
            "Epoch 179/200\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1059 - val_loss: 0.1452\n",
            "Epoch 180/200\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1056 - val_loss: 0.1450\n",
            "Epoch 181/200\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1052 - val_loss: 0.1444\n",
            "Epoch 182/200\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1049 - val_loss: 0.1441\n",
            "Epoch 183/200\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1047 - val_loss: 0.1437\n",
            "Epoch 184/200\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1043 - val_loss: 0.1433\n",
            "Epoch 185/200\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1040 - val_loss: 0.1429\n",
            "Epoch 186/200\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1037 - val_loss: 0.1427\n",
            "Epoch 187/200\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1034 - val_loss: 0.1422\n",
            "Epoch 188/200\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1031 - val_loss: 0.1418\n",
            "Epoch 189/200\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1029 - val_loss: 0.1415\n",
            "Epoch 190/200\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1025 - val_loss: 0.1412\n",
            "Epoch 191/200\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1023 - val_loss: 0.1407\n",
            "Epoch 192/200\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1020 - val_loss: 0.1404\n",
            "Epoch 193/200\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1017 - val_loss: 0.1402\n",
            "Epoch 194/200\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1014 - val_loss: 0.1398\n",
            "Epoch 195/200\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1011 - val_loss: 0.1395\n",
            "Epoch 196/200\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1009 - val_loss: 0.1391\n",
            "Epoch 197/200\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.1389\n",
            "Epoch 198/200\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1003 - val_loss: 0.1385\n",
            "Epoch 199/200\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1000 - val_loss: 0.1383\n",
            "Epoch 200/200\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0998 - val_loss: 0.1379\n",
            "training_acc:                                   0.969852\n",
            "test_acc: 0.9455\n"
          ]
        }
      ]
    }
  ]
}